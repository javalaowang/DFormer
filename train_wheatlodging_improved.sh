#!/bin/bash

# Wheatlodgingæ•°æ®é›†æ”¹è¿›è®­ç»ƒè„šæœ¬ - è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜
GPUS=1
NNODES=1
NODE_RANK=${NODE_RANK:-0}
PORT=${PORT:-29158}
MASTER_ADDR=${MASTER_ADDR:-"127.0.0.1"}

export CUDA_VISIBLE_DEVICES="0"
export TORCHDYNAMO_VERBOSE=1

echo "ğŸš€ å¼€å§‹æ”¹è¿›è®­ç»ƒ - è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜"
echo "ğŸ“Š ä½¿ç”¨é…ç½®: DFormer-Small + æ­£åˆ™åŒ– + æ—©åœ"
echo "ğŸ¯ ç›®æ ‡: æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ"

PYTHONPATH="$(dirname $0)/..":"$(dirname $0)":$PYTHONPATH \
    torchrun \
    --nnodes=$NNODES \
    --node_rank=$NODE_RANK \
    --master_addr=$MASTER_ADDR \
    --nproc_per_node=$GPUS \
    --master_port=$PORT \
    utils/train.py \
    --config=local_configs.Wheatlodgingdata.DFormer_Small_improved --gpus=$GPUS \
    --no-sliding \
    --no-compile \
    --syncbn \
    --mst \
    --compile_mode="default" \
    --no-amp \
    --val_amp \
    --no-use_seed

echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "ğŸ“ˆ è¯·æ£€æŸ¥è®­ç»ƒæ—¥å¿—å’ŒéªŒè¯æ›²çº¿"


