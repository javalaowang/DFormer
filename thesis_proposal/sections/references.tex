\begin{thebibliography}{99}

\bibitem{shah2019improving}
Shah L, Yahya M, Shah S M A, et al. Improving lodging resistance: Using wheat and rice as classical examples[J]. International Journal of Molecular Sciences, 2019, 20(17): 4211.

\bibitem{yin2025dformerv2}
Yin B, Cao J, Cheng M M, et al. DFormerv2: Rethinking RGBD representation learning for semantic segmentation with geometric self-attention[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2025: 1-11.

\bibitem{zhang2025vclr}
Zhang C B, Ni J, Zhong Y, et al. v-CLR: View-consistent learning for open-world instance segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2025: 1-12.

\bibitem{liu2018estimates}
Liu T, Li R, Zhong X, et al. Estimates of rice lodging using indices derived from UAV visible and thermal infrared images[J]. Agricultural and Forest Meteorology, 2018, 252: 144-154.

\bibitem{yang2017spatial}
Yang M D, Tseng H H, Hsu Y C, et al. Spatial and spectral hybrid image classification for rice lodging assessment through UAV imagery[J]. Remote Sensing, 2017, 9(6): 583.

\bibitem{zhang2020wheat}
Zhang J, Yuan L, Li R, et al. Wheat lodging detection based on fully convolutional neural network[J]. Computers and Electronics in Agriculture, 2020, 179: 105845.

\bibitem{wang2021rice}
Wang F, Yang M, Ma L, et al. Rice lodging detection using deep learning[J]. Plant Methods, 2021, 17(1): 1-12.

\bibitem{geirhos2019imagenet}
Geirhos R, Rubisch P, Michaelis C, et al. ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness[C]//International Conference on Learning Representations. 2019.

\bibitem{li2020high}
Li Y, Wen W, Guo X, et al. High-throughput plant height estimation from RGB-D images in greenhouse[J]. Biosystems Engineering, 2020, 197: 14-25.

\bibitem{hu2019acnet}
Hu X, Yang K, Fei L, et al. ACNet: Attention based network to exploit complementary features for RGBD semantic segmentation[C]//2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019: 1440-1444.

\bibitem{chen2021spatial}
Chen X, Lin K Y, Qian C, et al. Spatial information guided convolution for real-time RGBD semantic segmentation[J]. IEEE Transactions on Image Processing, 2021, 30: 2313-2324.

\bibitem{zhang2023cmx}
Zhang J, Liu H, Yang K, et al. CMX: Cross-modal fusion for RGB-X semantic segmentation with transformers[J]. IEEE Transactions on Intelligent Transportation Systems, 2023, 24(12): 14679-14694.

\bibitem{yin2024dformer}
Yin B, Zhang X, Li Z, et al. DFormer: Rethinking RGBD representation learning for semantic segmentation[C]//International Conference on Learning Representations. 2024.

\bibitem{geirhos2020shortcut}
Geirhos R, Jacobsen J H, Michaelis C, et al. Shortcut learning in deep neural networks[J]. Nature Machine Intelligence, 2020, 2(11): 665-673.

\bibitem{kim2020learning}
Kim M, Byun H. Learning texture invariant representation for domain adaptation of semantic segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 12975-12984.

\bibitem{lee2022wildnet}
Lee S, Seong H, Lee S, et al. WildNet: Learning domain generalized semantic segmentation from the wild[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 9936-9946.

\bibitem{atzberger2013advances}
Atzberger C. Advances in remote sensing of agriculture: Context description, existing operational monitoring systems and major information needs[J]. Remote Sensing, 2013, 5(2): 949-981.

\bibitem{veenendaal2017review}
Veenendaal B, Brovelli M A, Li S. Review of web mapping: Eras, trends and directions[J]. ISPRS International Journal of Geo-Information, 2017, 6(10): 317.

\bibitem{long2015fully}
Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.

\bibitem{ronneberger2015u}
Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2015: 234-241.

\bibitem{chen2018deeplab}
Chen L C, Zhu Y, Papandreou G, et al. Encoder-decoder with atrous separable convolution for semantic image segmentation[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 801-818.

\bibitem{xie2021segformer}
Xie E, Wang W, Yu Z, et al. SegFormer: Simple and efficient design for semantic segmentation with transformers[C]//Advances in Neural Information Processing Systems. 2021, 34: 12077-12090.

\bibitem{zhou2022canet}
Zhou H, Qi L, Huang H, et al. CANet: Co-attention network for RGB-D semantic segmentation[J]. Pattern Recognition, 2022, 124: 108468.

\bibitem{vaswani2017attention}
Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need[C]//Advances in Neural Information Processing Systems. 2017: 5998-6008.

\bibitem{dosovitskiy2021image}
Dosovitskiy A, Beyer L, Kolesnikov A, et al. An image is worth 16x16 words: Transformers for image recognition at scale[C]//International Conference on Learning Representations. 2021.

\bibitem{liu2021swin}
Liu Z, Lin Y, Cao Y, et al. Swin transformer: Hierarchical vision transformer using shifted windows[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 10012-10022.

\bibitem{sun2019rtfnet}
Sun Y, Zuo W, Liu M. RTFNet: RGB-thermal fusion network for semantic segmentation of urban scenes[J]. IEEE Robotics and Automation Letters, 2019, 4(3): 2576-2583.

\bibitem{zhang2012application}
Zhang C, Kovacs J M. The application of small unmanned aerial systems for precision agriculture: A review[J]. Precision Agriculture, 2012, 13(6): 693-712.

\bibitem{maes2019perspectives}
Maes W H, Steppe K. Perspectives for remote sensing with unmanned aerial vehicles in precision agriculture[J]. Trends in Plant Science, 2019, 24(2): 152-164.

\bibitem{chu2017assessing}
Chu T, Starek M J, Brewer M J, et al. Assessing lodging severity over an experimental maize (Zea mays L.) field using UAS images[J]. Remote Sensing, 2017, 9(9): 923.

\bibitem{wilke2019quantifying}
Wilke N, Siegmann B, Klingbeil L, et al. Quantifying lodging percentage and lodging severity using a UAV-based canopy height model combined with an objective threshold approach[J]. Remote Sensing, 2019, 11(5): 515.

\bibitem{zhao2017pyramid}
Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 2881-2890.

\bibitem{cheng2022masked}
Cheng B, Misra I, Schwing A G, et al. Masked-attention mask transformer for universal image segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 1290-1299.

\bibitem{kirillov2023segment}
Kirillov A, Mintun E, Ravi N, et al. Segment anything[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 4015-4026.

\bibitem{zhou2020learning}
Zhou K, Yang Y, Hospedales T, et al. Learning to generate novel domains for domain generalization[C]//European Conference on Computer Vision. Springer, 2020: 561-578.

\bibitem{yue2019domain}
Yue X, Zhang Y, Zhao S, et al. Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019: 2100-2110.

\bibitem{huang2018uav}
Huang Y, Reddy K R, Fletcher R S, et al. UAV low-altitude remote sensing for precision weed management[J]. Weed Technology, 2018, 32(1): 2-6.

\bibitem{eigen2014depth}
Eigen D, Puhrsch C, Fergus R. Depth map prediction from a single image using a multi-scale deep network[C]//Advances in Neural Information Processing Systems. 2014: 2366-2374.

\bibitem{schonberger2016structure}
Schonberger J L, Frahm J M. Structure-from-motion revisited[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 4104-4113.

\bibitem{murakami2012canopy}
Murakami T, Yui M, Amaha K. Canopy height measurement by photogrammetric analysis of aerial images: Application to buckwheat (Fagopyrum esculentum Moench) lodging evaluation[J]. Computers and Electronics in Agriculture, 2012, 89: 70-75.

\bibitem{he2016deep}
He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 770-778.

\bibitem{lin2017feature}
Lin T Y, Dollár P, Girshick R, et al. Feature pyramid networks for object detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 2117-2125.

\bibitem{chen2020simple}
Chen X, Yuan Y, Zeng G, et al. Semi-supervised semantic segmentation with cross pseudo supervision[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 2613-2622.

\bibitem{tarvainen2017mean}
Tarvainen A, Valpola H. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results[C]//Advances in Neural Information Processing Systems. 2017: 1195-1204.

\bibitem{zhou2017scene}
Zhou B, Zhao H, Puig X, et al. Scene parsing through ADE20K dataset[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 633-641.

\bibitem{silberman2012indoor}
Silberman N, Hoiem D, Kohli P, et al. Indoor segmentation and support inference from RGBD images[C]//European Conference on Computer Vision. Springer, 2012: 746-760.

\bibitem{song2015sun}
Song S, Lichtenberg S P, Xiao J. SUN RGB-D: A RGB-D scene understanding benchmark suite[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 567-576.

\bibitem{cordts2016cityscapes}
Cordts M, Omran M, Ramos S, et al. The cityscapes dataset for semantic urban scene understanding[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 3213-3223.

\bibitem{paszke2019pytorch}
Paszke A, Gross S, Massa F, et al. PyTorch: An imperative style, high-performance deep learning library[C]//Advances in Neural Information Processing Systems. 2019, 32.

\bibitem{wang2018understanding}
Wang X, Girshick R, Gupta A, et al. Non-local neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 7794-7803.

\bibitem{bai2021advancing}
Bai J, Yang S, Chen Y. Advancing agriculture: The role of deep learning in crop disease detection and yield prediction[J]. Agricultural Systems, 2021, 193: 103233.

\bibitem{kamilaris2018deep}
Kamilaris A, Prenafeta-Boldú F X. Deep learning in agriculture: A survey[J]. Computers and Electronics in Agriculture, 2018, 147: 70-90.

\bibitem{liakos2018machine}
Liakos K G, Busato P, Moshou D, et al. Machine learning in agriculture: A review[J]. Sensors, 2018, 18(8): 2674.

\bibitem{zhao2018object}
Zhao H, Shi J, Qi X, et al. Pyramid scene parsing network[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2018, 42(2): 386-399.

\bibitem{yuan2021hrformer}
Yuan Y, Fu R, Huang L, et al. HRFormer: High-resolution vision transformer for dense predict[C]//Advances in Neural Information Processing Systems. 2021, 34: 7281-7293.

\bibitem{strudel2021segmenter}
Strudel R, Garcia R, Laptev I, et al. Segmenter: Transformer for semantic segmentation[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 7262-7272.

\bibitem{liu2022convnet}
Liu Z, Mao H, Wu C Y, et al. A ConvNet for the 2020s[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 11976-11986.

\end{thebibliography}

